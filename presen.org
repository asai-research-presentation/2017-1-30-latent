#+title: Classical Planning in Deep Latent Space
#+author: Masataro Asai
#+include: "head.org"
#+LINK: img file:img/%s
#+LINK: png file:img/%s.png
#+LINK: jpg file:img/%s.jpg
#+LINK: svg file:img/%s.svg
#+LINK: spng file:img/static/%s.png
#+LINK: sjpg file:img/static/%s.jpg
#+LINK: ssvg file:img/static/%s.svg

#+BEGIN_outline-text-1
#+BEGIN_CENTER
東京大学大学院 博士2年

総合文化研究科　(渋谷駒場キャンパス)

学振DC2

浅井 政太郎
#+END_CENTER

#+BEGIN_NOTE
#+BEGIN_ALIGNRIGHT
Made by guicho2.71828 (Masataro Asai)
#+END_ALIGNRIGHT
#+END_NOTE
#+END_outline-text-1

* 今日の発表の Motivation                                          :noexport:

#+BEGIN_CONTAINER-FLUID
#+BEGIN_ROW-FLUID
#+BEGIN_SPAN5
|      |                  |
|------+------------------|
| ~'70 | 第一次AIブーム   |
| ~'80 | *第一次AIの冬*   |
| ~'90 | 第二次AIブーム   |
| ~'08 | *第二次AIの冬*   |
| '08~ | 第三次AIブーム   |
| ???? | *第三次AIの冬??* |
#+END_SPAN5
#+BEGIN_SPAN7
+ 第二次AIの冬の原因:
  + *論理だけで全てが*

    *解決できると考えた*
  + 現実世界 (物体、アクション) のラベルを手入力する必要があった
  + ソルバも遅すぎた (ハードウェアも遅かったが、探索手法も指数的に非効率)
+ 現在: *より速いソルバがある*
+ 現在: *ラベル付も Deep Learning でできそうだ*
#+END_SPAN7
#+END_ROW-FLUID
#+END_CONTAINER-FLUID

+ 第三次AIの冬のありそうな原因: *Deep Learningで全てが解決できると考えた?*
  + 脳科学(笑) シンギュラリティ(笑)

* 高度に知的な機械を作るには → DeepLearning + 論理と推論

#+BEGIN_CENTER
#+BEGIN_CONTAINER-FLUID
#+BEGIN_ROW-FLUID
#+BEGIN_SPAN5
ディープラーニングのみ

↓

虫程度の知能を持った

*反射的な機械*
#+END_SPAN5
#+BEGIN_SPAN2
　

vs

　
#+END_SPAN2
#+BEGIN_SPAN5
DL + *論理、推論、思考*

↓

目標を達成するために

*論理で戦略を練る機械*

#+END_SPAN5
#+END_ROW-FLUID
#+END_CONTAINER-FLUID
#+END_CENTER

[[png:planning-deeplearning]]
* ゴール

#+BEGIN_XLARGE
#+BEGIN_CENTER
State of the Art

Deep Learning 

＋

State of the Art

Classical Planning
#+END_CENTER
#+END_XLARGE

* スライディング タイル パズル (8-Puzzle)

空きパネルとそれ以外を移動させることで絵を完成させるパズル

[[sjpg:puzzle]]

#+BEGIN_ALIGNRIGHT
*古典的なAI問題として知られている*

可能な曲面の数は 362880 個

4x4の15-パズル、5x5の24-パズルはさらに難しい
#+END_ALIGNRIGHT

* Overview

8-Puzzle を解く論理に基づくAIを作る

 *ヒント・棋譜なし* : *棋譜から学習した勘で解くAlphaGoと異なる*

[[sjpg:puzzle]]

** Overview

[[png:overview/1]]

** Overview

[[png:overview/2]]

** Overview

#+HTML: <embed src="img/overview/3.svg" type="image/svg+xml"  />

* Introduction

#+BEGIN_XLARGE
#+BEGIN_CENTER
There's No Silver Bullet!!
#+END_CENTER
#+END_XLARGE

* Deep Neural Networks

とてもはやっている

　

　

[[png:deeplearning1]]

** Deep Neural Networks

とてもはやっている

ベクトル (データ) と 行列W (重み) の掛け算 

　

[[png:deeplearning2]]

** Deep Neural Networks

とてもはやっている

ベクトル (データ) と 行列W (重み) の掛け算 

→ 出力の誤差=微分を使ってWを更新 → 学習完了

[[png:deeplearning3]]


** 認知タスクで人間に匹敵する精度

[[png:dl-image-task]]

** 認知タスクで人間に匹敵する精度

[[png:dl-nlp-task]]

** ニューラルネットの役割

#+BEGIN_CENTER
「直感的な」問題を解く *関数* を学習すること
#+END_CENTER

+ 求めるべき関数 $y^*=f^*(x)$
  
  | タスク   | 入力x      | 出力y                      |
  |----------+------------+----------------------------|
  | 画像分類 | 画像       | ラベル(車、ネコ、猿・・・) |
  | 翻訳     | 文章(日)   | 文章(英)                   |
  | 未来予測 | フレーム列 | 次のフレーム               |

+ NNが表す関数　 $y=f(x)$

#+BEGIN_CENTER
+ 学習 ≡ 誤差 $||y-y^*||$ を最小化する最適化問題
#+END_CENTER

** NNは複雑な問題を魔法のように解くことが出来る

#+BEGIN_LARGER
なぜなら

#+BEGIN_indent
  + 人間は賢くてニューロンで動く し、
  + ニューロンある = 賢さの証明 だし、
  + 賢ければ何でも出来て当然 だし、
  + 将来はシンギュラリティに溢れてて当然。
  + ...
  + ハァ?
#+END_indent
#+END_LARGER

** 

[[png:dl-silver-bullet]]

** NNは複雑な問題を魔法のように解くことができる?

#+BEGIN_CONTAINER-FLUID
#+BEGIN_ROW-FLUID
#+BEGIN_SPAN6
+ *出来る派の意見:*
+ 人間は賢くてニューロンで動く
+ ニューロン = 賢い
+ 賢い機械はスゴイからニューロンだ
+ 脳科学でシンギュラっちゃうぜ！

  ※ 画像はイメージ
  
  [[spng:ai_pet_family]]
#+END_SPAN6
#+BEGIN_SPAN6
+ *出来ない派の意見:*
+ プラナリアも神経系を持つが賢い??
+ *Is humanity /so/ smart?*
+ *Not necessarily↓*

  ※ 画像はイメージ
  
  [[spng:mizuho]]
  
  [[sjpg:trump]]
#+BEGIN_ALIGNRIGHT
#+END_ALIGNRIGHT
#+END_SPAN6
#+END_ROW-FLUID
#+END_CONTAINER-FLUID

** No Silver Bullet: NNで複雑な問題を魔法のように解くことはできない・・・と思われる2 :noexport:

+ 出来る派のもう少しマシな意見:
  + NN は Turing完全, アナログNNは Super Turing (Siegelmann, 95, Science)
  + 二段以上のNNは 十分な数のノードがあれば どんな関数でも表現可能

+ *出来ない派のもう少し真面目な反論*:
  + *表現できる != 学習できる*
  + *構造の単純な関数しか学習できない*
    + *Gradient Descent の亜種で解けるような関数*
    + *局所解は大域最適解である??*

*** Gradient Descent (再急降下法)

傾きの大きい方向に向かって進む

[[spng:gradient-descent]]

#+BEGIN_CENTER
*一般には: 最適解でないところに到達する可能性がある*

*NNでは: 局所解はほぼ確実に大域最適解である == 無視*
#+END_CENTER

#+BEGIN_NOTE
SGDでも基本的な想定は一緒
#+END_NOTE

*** 進化計算などで解かれるRastrigin関数 (例)

#+BEGIN_CENTER
こういう関数は SGD では解けない

→ *NNでは学習できない種類の構造も存在する*
#+END_CENTER
   
[[sjpg:rastrigin]]

** No Silver Bullet: NNで複雑な問題を魔法のように解くことはできない・・・と思われる3

+ 出来ない派のもう少し真面目な反論2:
  + *認知タスクと比べ、論理思考タスクは人間にも難しい*
    + *人間の物体認識: 1秒以下*
    + *大学入試数学の証明問題: 25分*
    + 明らかに *難しさの質に差がある*
  + 難しさの質というのはどうやって測る?
    + 理論的解析: *計算量理論* (NP困難とか)
  # + *論理思考タスクは計算量理論的に困難な問題が多数*
  #   + *NP困難以上: 最悪指数時間*
  #   + *← 学習に指数時間かかる = 解けないのと同じ*

*** 学習が終わるのは

[[sjpg:利根川]]

** 

#+BEGIN_XLARGE
#+BEGIN_CENTER
ニューラルネットは

銀の弾ではない

従って、ブームではあるが・・・
#+END_CENTER
#+END_XLARGE

** 

[[sjpg:fukashigi]]
* AI Topics -- プランニングへのイントロダクション(再び)

#+BEGIN_QUOTE
「これがDLの次にあるもうひとつの人工知能だ」
#+END_QUOTE

** 誰?

 #+BEGIN_CONTAINER-FLUID
 #+BEGIN_ROW-FLUID
 #+BEGIN_SPAN6
 [[png:astro/1]]
 #+END_SPAN6
 #+BEGIN_SPAN6
 [[png:rescue/1]]
 #+END_SPAN6
 #+END_ROW-FLUID
 #+END_CONTAINER-FLUID

  #+BEGIN_RESUME
  And let me introduce these robots.
  The guy in the left is Astro boy.
  #+END_RESUME

*** 誰?

 #+BEGIN_CONTAINER-FLUID
 #+BEGIN_ROW-FLUID
 #+BEGIN_SPAN6
 [[png:astro/2]]
 #+END_SPAN6
 #+BEGIN_SPAN6
 [[png:rescue/1]]
 #+END_SPAN6
 #+END_ROW-FLUID
 #+END_CONTAINER-FLUID

 #+BEGIN_RESUME
 As you know, he is a famous manga superhero invented by Tezuka Osamu in 50s,
 #+END_RESUME

*** 誰?

  #+BEGIN_CONTAINER-FLUID
  #+BEGIN_ROW-FLUID
  #+BEGIN_SPAN6
  [[png:astro/final]]
  #+END_SPAN6
  #+BEGIN_SPAN6
  [[png:rescue/1]]
  #+END_SPAN6
  #+END_ROW-FLUID
  #+END_CONTAINER-FLUID

 #+BEGIN_RESUME
 and he can think, hear, speak, act. he also has emotions.
 #+END_RESUME

*** 誰?

  #+BEGIN_CONTAINER-FLUID
  #+BEGIN_ROW-FLUID
  #+BEGIN_SPAN6
  [[png:astro/final]]
  #+END_SPAN6
  #+BEGIN_SPAN6
  [[png:rescue/2]]
  #+END_SPAN6
  #+END_ROW-FLUID
  #+END_CONTAINER-FLUID

 #+BEGIN_RESUME
  In contrast, the guy in the right is a real robot that is actually in use @ fukuoka prefecture for the rescue purpose..
  His name is T-52 Enryu, developped by a Japanese company Temzak.
  He is huge and powerful -- about 4 meters in height and can carry things which is as heavy as 500kg.
  Well, so, in a sense, he is also a superhero in the real disastrous situation.
 #+END_RESUME

*** 誰?

  #+BEGIN_CONTAINER-FLUID
  #+BEGIN_ROW-FLUID
  #+BEGIN_SPAN6
  [[png:astro/final]]
  #+END_SPAN6
  #+BEGIN_SPAN6
  [[png:rescue/3]]
  #+END_SPAN6
  #+END_ROW-FLUID
  #+END_CONTAINER-FLUID

 #+BEGIN_RESUME
 But does he have feelings or can he think? Can he even move around by his own?
 #+END_RESUME

*** 誰?

  #+BEGIN_CONTAINER-FLUID
  #+BEGIN_ROW-FLUID
  #+BEGIN_SPAN6
  [[png:astro/final]]
  #+END_SPAN6
  #+BEGIN_SPAN6
  [[png:rescue/final]]
  #+END_SPAN6
  #+END_ROW-FLUID
  #+END_CONTAINER-FLUID

 #+BEGIN_RESUME
 No. It requires full human intervention --- it is indeed operated by a
 driver who gets in or by a remote control. It is more like a
 super-sophisticated shovel car.
 #+END_RESUME

** 実際の大規模災害では非実用的 --- 操縦士が足りない!

 #+BEGIN_CONTAINER-FLUID
 #+BEGIN_ROW-FLUID
 #+BEGIN_SPAN2
 [[png:rescue]]
 [[png:rescue]]
 [[png:rescue]]
 [[png:silent]]
 #+END_SPAN2
 #+BEGIN_SPAN10
 [[jpg:static/tsunami]]
 #+END_SPAN10
 #+END_ROW-FLUID
 #+END_CONTAINER-FLUID

 #+BEGIN_LARGER
 #+BEGIN_ALIGNRIGHT
 + そのままでは役に立たない!
 #+END_ALIGNRIGHT
 #+END_LARGER

 #+BEGIN_RESUME
 Now the problem is : It's ok in small accidents but is impractical in the real, massive 
 natural disaster which frequently occurs in Japan.
 The key resource is human ---
 These special purpose vehicles require human intervention,
 thus they are useless without trained operators.
 #+END_RESUME

*** 操縦士を増やせない -- Human Resource and Training

 #+BEGIN_CONTAINER-FLUID
 #+BEGIN_ROW-FLUID
 #+BEGIN_SPAN4
  [[png:rescue/1]]
 #+END_SPAN4
 #+BEGIN_SPAN8

   + ✘ /時間/ がかかる :: 訓練に ＞100時間, *必要な時だけ増やす* のは不可能
   + ✘ /￥￥￥￥/ がかかる :: 訓練官、訓練場所、訓練用具
   + ✘ 技術は /維持が重要/ :: 定期的な再訓練、長期的コスト、さらなるマニー
   + ✘ 平時は /無駄/ な技術 :: 普段は意味がない -- 無駄なマニー!
 #+END_SPAN8
 #+END_ROW-FLUID
 #+END_CONTAINER-FLUID

 #+BEGIN_RESUME
 In a natural disaster, we need as many experienced operators as possible.
 However, it is virtually impossible due to several reasons. 

 First, training takes time.
 It is impossible to quickly increase the number of operators as needed, at the time of disaster.

 Second, the money matters.
 Training a person costs a lot of money, including: the cost of maintaining
 a training center, the cost of additional vehicles for training, the cost
 of training the trainers, wages for trainers, etc.

 Third, Skills need to be updated and maintained.
 You know, how about preparing the large number of operators in advance?
 No, the society cannot torelate the cost of keep training them.
 Operators may lose the skills and skills may become outdated.

 Finally, in a normal situation, those skills are useless.
 It forces the society to waste a great amount of extra money.
 #+END_RESUME

** だからこそ: 自動プランナ Automated Planner

 [[png:planning/1]]

 #+BEGIN_RESUME
 研究テーマのプランニングは、ロボットに、人間の助けを借りず、いかに自律して行動させるかを扱います。
 これをモデル化したプランニング問題は、具体的な行動の列を求める 組合せ最適化問題です。

 プランニング問題のタスクは、
 センサーから初期状態とゴールを受け取って、被災者を助ける正しい手順を出力することです。

 たとえば、この図では男性が瓦礫に埋まって助けを求めています。
 プランニング機能のあるロボットは、コレに対して「男性を助けよ」という大まかな指示を受けます。
 #+END_RESUME

** だからこそ: 自動プランナ Automated Planner

 [[png:planning/2]]

 #+BEGIN_RESUME
 指示の内容には、図のように初期状態とゴール、許可された行動のリストが入っています。
 ロボットは、自動プランニングにより、人間の代わりに適切な行動を組み立てて、ゴールを自動で達成します。
 #+END_RESUME

** だからこそ: 自動プランナ Automated Planner

 [[png:planning/final]]

 #+BEGIN_RESUME
 プランニングは汎用な枠組みなので、災害救助以外にも様々な問題に適用することができます。
 現実の応用例では「宇宙探査機運行問題」や「企業ネットワーク脆弱性問題」も表現できます。

 このように、プランニングは、難しい問題を汎用性を失わずに解くことを目指します。
 #+END_RESUME

 # 自動運転事故:
 # ポリシーが決まっていないならそういうものは作るべきではない
 # 危険だ

 # しかし自動運転は自分の扱うプランニングとは違うので実は困らない

 # ゴール設定は人間がやればいい
 # ターゲットを決めた上で
 # 全力で考えるのがプランニングの技術
 # 効用関数を決めるのは人間
 # いかにそれを実現するか
 # あくまで命令に従うロボットであることを強調

 # ドメインは消す
 # アプリケーション
 # 
 # coreまでは実例
 # 災害援助は将来
 # 完全に分離
 # 
 # 掃除ドメインをメインに

 # ** プランニングとは?
 # 
 # [[png:planning-4room]]

 # #+BEGIN_RESUME
 # 同じ掃除ドメインの4部屋インスタンスも表現できますし、
 # 現実の応用例では「宇宙探査ドメイン」も表現できます。
 # 
 # このように、プランニングは、難しい問題を汎用性を失わずに解くことを目指します。
 # 
 # 仮に将来、写真のような救助ロボットにプランニングソルバを組み込めば、
 # 被災者を発見した時に適切な行動を自ら選択できるようになるかもしれません。
 # #+END_RESUME

** AIの使いドコロ  :noexport:

 + 人では不可能な作業の代替 :: 危険な環境, 宇宙空間・深海, 24時間対応, マイクロ秒応答
 + コストのかかる専門技師の代替・自動化 :: 機械工作, 人工衛星運営(専門家会議の時給が高い!)
 + ミスの許されない完璧な理論保証の求められる問題の求解 :: 半導体のバグ検証システム(生産を始めると止められない)

** AIと自動プランニング の位置づけ -- /理論/ と /実応用/ の中間  :noexport:

 緑は /理論/ 、オレンジは /実応用/ 、 AI はその橋渡し (どれともかぶらない部分もある)

 #+BEGIN_RESUME
 Automated Planning is a branch of Aritificial Intelligence. 

 It shares a lot of technology with Operations Research and Theoretical
 Computer Science, and is considered a bridge between pure theory and
 pure applications.
 #+END_RESUME

 [[png:planning2]]
* プランニング問題 (決定的,完全情報) -- Blocksworld

#+HTML: <embed src="img/plan.svg" type="image/svg+xml"  />

** アクション = 条件付き状態遷移

#+BEGIN_CENTER
#+BEGIN_XLARGE
アクション (move ?X ?Y)
#+END_XLARGE
#+END_CENTER

#+BEGIN_CENTER
*?X*, *?Y* : 変数。 値 *BLOCK-A*, *BLOCK-B* などを適用して使う

*前提条件* と *効果* で構成される
#+END_CENTER
#+BEGIN_QUOTE
*前提条件* が満たされた時…

命題 (clear *?X*) : 積み木 *?X* の上に何も置かれていない

命題 (clear *?Y*) : 積み木 *?Y* の上に何も置かれていない

*効果* を適用

⇒ 命題 (on *?X* *?Y*) を追加 : *?X* が *?Y* の上に移動

⇒ 命題 (clear *?Y*) を削除 : *?Y* は clear ではなくなる
#+END_QUOTE

** *PDDL* : Planning Domain Description Language

現在も International Planning Competition の入力形式として使われている。

#+BEGIN_CONTAINER-FLUID
#+BEGIN_ROW-FLUID
#+BEGIN_SPAN2

#+END_SPAN2
#+BEGIN_SPAN8
#+BEGIN_SRC lisp
(:action move
 :parameters (?X ?Y)
 :preconditions
   (and (clear ?X)   ; (1)
        (clear ?Y))  ; (2)

 :effect
   (and (on ?X ?Y)   ; (3)
        (not         ; (4)
         (clear ?Y))))
#+END_SRC
#+END_SPAN8
#+BEGIN_SPAN2

#+END_SPAN2
#+END_ROW-FLUID
#+END_CONTAINER-FLUID

#+BEGIN_NOTE
宇宙探査機 NASA DS1 上の Remote Agent 自動航行システム でも
 "DDL" という名で 似たような記述言語があったようだ
#+END_NOTE

** プランニング = グラフ探索

*ノード* : 状態 = 命題の集合 ⇒ =(on A B)=, =(clear A)= など

*辺*     : アクション ⇒ =(move A B)= 等

[[png:graph]]

# #+BEGIN_CONTAINER-FLUID
# #+BEGIN_ROW-FLUID
# #+BEGIN_SPAN6
# # + ヒューリスティック探索 A*
# # + State-of-the-Art *1
# #+END_SPAN6
# #+BEGIN_SPAN6
# # #+attr_html: :width 50%
# #+END_SPAN6
# #+END_ROW-FLUID
# #+END_CONTAINER-FLUID

#+BEGIN_NOTE
*1 [Helmert, 2006] [Richter, 2010]
#+END_NOTE
  



** Q. はやりのDeep Learningとの違いは?

 A. レイヤが違う

 #+BEGIN_CONTAINER-FLUID
 #+BEGIN_ROW-FLUID
 #+BEGIN_SPAN6
 *機械学習・Neural Networks* 
 
 for *認識・反射*
 + 入力 は *Subsymbolic* (連続値)
   
   画像、音声、非構造化テキスト: 
 + *直感/脊髄反射的知能*:
   
   　 *_直後_ の行動の決定*
   #+BEGIN_SMALLER
   *パブロフの犬* : 餌→よだれ

   *自動運転* : 赤信号,人 → 止まる.

   *翻訳* : 文章 → 文章

   *囲碁局面の評価関数* : 局面 → 勝率
   #+END_SMALLER
   ☺ 効率よく 1-to-1 mapping
   
   ☹ 単純作業
 #+END_SPAN6
 #+BEGIN_SPAN6
 *推論・探索*

 for *プランニング・ゲーム・定理証明*
 + 入出力は *Symbolic*
   
   論理 オブジェクト ルール
 + *論理・推論による知能:*

   　 *_未来に渡る_ 戦略の決定*
   
   　 (戦略 = 行動の *列や木*)
   #+BEGIN_SMALLER
   *レスキューロボ* : ゴール = 被災者生存

   *証明器* : ゴール = QED

   *コンパイラ* : 命令列の生成
   
   *囲碁,将棋* : ゴール = 勝利
   #+END_SMALLER
   #+BEGIN_LARGER
   ☺ 多数の論理の組み合わせ
   #+END_LARGER
 #+END_SPAN6
 #+END_ROW-FLUID
 #+END_CONTAINER-FLUID

AlphaGo = Subsymbolic (DLNNによる評価関数の学習) + Symbolic (UCT-MCTSによる探索)

** 既存の有名システム

+ AlphaGo = Subsymbolic (DLNNによる評価関数の学習) + Symbolic (UCT-MCTSによる探索)
  + ただし *囲碁に特化*, かつ *膨大な棋譜が必要*
  + 自律的なエージェントは *未知の状況に推論により対処しなくてはならない* → まだ完璧ではない
+ DQN = DLNN (*Subsymbolic*) + Reinforcement Learning (*Subsymbolic*)
  + 様々な Atari Game につかえる汎用的なフレームワーク (Invader, Packman…) だが
  + ほとんどのゲームは *脊髄反射的な操作で長く生き残ることが出来る*
  + *Atari をプレイする上で 複雑な論理思考能力は必要ない*
  + だからこそRLで成功した

#+BEGIN_NOTE
DLNN: Deep Learning Neural Network

UCT-MCTS: Monte Carlo Tree Search + Universal Confidence Bound applied on Trees
#+END_NOTE
* システム概要

 [[png:overview/planning]]

** State Autoencoder

 [[png:overview/state-ae]]

** Autoencoder

#+BEGIN_CENTER
*教師なし学習*

入力空間 *S* を Latent Space *L* に *圧縮*

かつ *S* に *展開* して *元の画像に損失無く戻す。*
#+END_CENTER

#+BEGIN_CONTAINER-FLUID
#+BEGIN_ROW-FLUID
#+BEGIN_SPAN3

#+END_SPAN3
#+BEGIN_SPAN6
[[png:static/autoenc]]
#+END_SPAN6
#+BEGIN_SPAN3

#+END_SPAN3
#+END_ROW-FLUID
#+END_CONTAINER-FLUID

#+BEGIN_ALIGNRIGHT
→ *データ* $x$ を *Latent vector* $z$ に変換/逆変換するNNを学習
#+END_ALIGNRIGHT

** Deep Autoencoder

 いろいろな追加技術を使うことでDeepにできる → *より圧縮できる*

 Stacked AE, pretraining, CNN, dropout, Batch-Normalization, GPU...

 [[png:static/deep-ae]]

** State Autoencoder

 [[png:overview/state-ae]]

** Gumbel-Softmax (Jang, Gu, ICLR2017?)

 *入力をカテゴリカル分布にマップする* Activation Function 

#+BEGIN_CENTER
 #+BEGIN_HTML
 <svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" width="649px" height="206px" version="1.1" content="&lt;mxfile userAgent=&quot;Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/54.0.2840.71 Safari/537.36&quot; version=&quot;6.0.1.2&quot; editor=&quot;www.draw.io&quot; type=&quot;google&quot;&gt;&lt;diagram name=&quot;Page-1&quot;&gt;3ZhLc5swEMc/Dcd0kAQCX+O67SGd6TTTaXqU0fJoZcsjy69++oogDBjs0MZ2TONDpL9ey29Xi5BDxrPtR8UW6WfJQTjY5VuHvHcwxshF5l+u7AqF+rgQEpXxQkKV8Jj9Biu6Vl1lHJaNjlpKobNFU4zkfA6RbmhMKblpdoulaK66YAm0hMeIibb6PeM6LdTQdyv9E2RJWq6MXNsyY2VnKyxTxuWmJpGJQ8ZKSl2UZtsxiBxeyaUY9+FI694wBXPdZ0AQh1EYx4xP46kXRHBnZ1gzsbIPaw3Vu/LpN2mm4XHBory+MR52yH2qZ8LUkCnGmRBjKaR67k0AcR8Coy+1kr+g1jKiAWHUtCi5mnPgdrw1AJSG7dGnQntWJshAzkCrneliB5CAFENsfCHPL+qbylt7n6Q1T+HAisxGSLKfu4JoCpZjT6a4xRT71MFUmFXvebY2xSQvfoWHb6VsFqm1tHygUjmbroyR9y944ww08QFN7LktmmEHzPASLEmLpY/wcFiiW2LptVAAN3nOVqXSqUzknIlJpdb2qtuEA9tMP9XKP/Iu7/y8NjeGPtkRz5Wq7SdovbMJnq20NFK17oOUiwb63LzT4M3TyJWK4HT0aKYS0Kd2a9uBCgTT2bq5/mvc4eEIU4xG4PsesCDqCO1z+ufKpBHugZq8FeorRf6VmfdBfiQ9XR45HXbi9kf4zRJ3i2Uw7AOFd0ssw//9JXgseupponu3Ht8MwYEDL+KZ0cDehyeBBqd3BB31B2pn+SIzY0D/KYqYsKMO3LK36N88hc7+1cgZhHHU9dVIoxCm8SW+GukINQm67bSEaEde2otnDX901nAfRGaiPTYSutYJ5uiRdthRfldeot1IlPfI8i9Abcb8AeLYz3+diJ//Xgm1hIg6IHpdEL1LQCxvEwcK0Q4I3IP8+8ZQX/9SuwGoJGxud+STFtSQtpli3/trpqZa3VwX54rq/p9M/gA=&lt;/diagram&gt;&lt;/mxfile&gt;"><defs/><g transform="translate(0.5,0.5)"><rect x="288" y="0.75" width="75" height="202.5" rx="11.25" ry="11.25" fill="#e1d5e7" stroke="#9673a6" pointer-events="none"/><path d="M 243 72 L 273 102 L 243 132 L 213 102 Z" fill="#ffffff" stroke="#000000" stroke-miterlimit="10" pointer-events="none"/><g transform="translate(231.5,91.5)scale(0.75)"><switch><foreignObject style="overflow:visible;" pointer-events="all" width="30" height="26" requiredFeatures="http://www.w3.org/TR/SVG11/feature#Extensibility"><div xmlns="http://www.w3.org/1999/xhtml" style="display: inline-block; font-size: 12px; font-family: Helvetica; color: rgb(0, 0, 0); line-height: 1.2; vertical-align: top; width: 32px; white-space: nowrap; word-wrap: normal; text-align: center;"><div xmlns="http://www.w3.org/1999/xhtml" style="display:inline-block;text-align:inherit;text-decoration:inherit;">256<div>ReLU</div></div></div></foreignObject><text x="15" y="19" fill="#000000" text-anchor="middle" font-size="12px" font-family="Helvetica">[Not supported by viewer]</text></switch></g><path d="M 168 72 L 198 102 L 168 132 L 138 102 Z" fill="#ffffff" stroke="#000000" stroke-miterlimit="10" pointer-events="none"/><g transform="translate(156.5,91.5)scale(0.75)"><switch><foreignObject style="overflow:visible;" pointer-events="all" width="30" height="26" requiredFeatures="http://www.w3.org/TR/SVG11/feature#Extensibility"><div xmlns="http://www.w3.org/1999/xhtml" style="display: inline-block; font-size: 12px; font-family: Helvetica; color: rgb(0, 0, 0); line-height: 1.2; vertical-align: top; width: 32px; white-space: nowrap; word-wrap: normal; text-align: center;"><div xmlns="http://www.w3.org/1999/xhtml" style="display:inline-block;text-align:inherit;text-decoration:inherit;">512<div>ReLU</div></div></div></foreignObject><text x="15" y="19" fill="#000000" text-anchor="middle" font-size="12px" font-family="Helvetica">[Not supported by viewer]</text></switch></g><path d="M 198 102 L 208.22 102" fill="none" stroke="#000000" stroke-miterlimit="10" pointer-events="none"/><path d="M 212.16 102 L 206.91 104.63 L 208.22 102 L 206.91 99.38 Z" fill="#000000" stroke="#000000" stroke-miterlimit="10" pointer-events="none"/><path d="M 120.75 102 L 135.75 102 L 123 102 L 133.22 102" fill="none" stroke="#000000" stroke-miterlimit="10" pointer-events="none"/><path d="M 137.16 102 L 131.91 104.63 L 133.22 102 L 131.91 99.38 Z" fill="#000000" stroke="#000000" stroke-miterlimit="10" pointer-events="none"/><path d="M 273 102 L 288 102 L 273 102 L 283.22 102" fill="none" stroke="#000000" stroke-miterlimit="10" pointer-events="none"/><path d="M 287.16 102 L 281.91 104.63 L 283.22 102 L 281.91 99.38 Z" fill="#000000" stroke="#000000" stroke-miterlimit="10" pointer-events="none"/><path d="M 482.25 72 L 512.25 102 L 482.25 132 L 452.25 102 Z" fill="#ffffff" stroke="#000000" stroke-miterlimit="10" pointer-events="none"/><g transform="translate(470.5,91.5)scale(0.75)"><switch><foreignObject style="overflow:visible;" pointer-events="all" width="30" height="26" requiredFeatures="http://www.w3.org/TR/SVG11/feature#Extensibility"><div xmlns="http://www.w3.org/1999/xhtml" style="display: inline-block; font-size: 12px; font-family: Helvetica; color: rgb(0, 0, 0); line-height: 1.2; vertical-align: top; width: 32px; white-space: nowrap; word-wrap: normal; text-align: center;"><div xmlns="http://www.w3.org/1999/xhtml" style="display:inline-block;text-align:inherit;text-decoration:inherit;">512<div>ReLU</div></div></div></foreignObject><text x="15" y="19" fill="#000000" text-anchor="middle" font-size="12px" font-family="Helvetica">[Not supported by viewer]</text></switch></g><path d="M 407.25 72 L 437.25 102 L 407.25 132 L 377.25 102 Z" fill="#ffffff" stroke="#000000" stroke-miterlimit="10" pointer-events="none"/><g transform="translate(395.5,91.5)scale(0.75)"><switch><foreignObject style="overflow:visible;" pointer-events="all" width="30" height="26" requiredFeatures="http://www.w3.org/TR/SVG11/feature#Extensibility"><div xmlns="http://www.w3.org/1999/xhtml" style="display: inline-block; font-size: 12px; font-family: Helvetica; color: rgb(0, 0, 0); line-height: 1.2; vertical-align: top; width: 32px; white-space: nowrap; word-wrap: normal; text-align: center;"><div xmlns="http://www.w3.org/1999/xhtml" style="display:inline-block;text-align:inherit;text-decoration:inherit;">256<div>ReLU</div></div></div></foreignObject><text x="15" y="19" fill="#000000" text-anchor="middle" font-size="12px" font-family="Helvetica">[Not supported by viewer]</text></switch></g><path d="M 437.25 102 L 447.47 102" fill="none" stroke="#000000" stroke-miterlimit="10" pointer-events="none"/><path d="M 451.41 102 L 446.16 104.63 L 447.47 102 L 446.16 99.38 Z" fill="#000000" stroke="#000000" stroke-miterlimit="10" pointer-events="none"/><path d="M 360 102 L 375 102 L 362.25 102 L 372.47 102" fill="none" stroke="#000000" stroke-miterlimit="10" pointer-events="none"/><path d="M 376.41 102 L 371.16 104.63 L 372.47 102 L 371.16 99.38 Z" fill="#000000" stroke="#000000" stroke-miterlimit="10" pointer-events="none"/><rect x="526.5" y="42" width="120" height="120" rx="18" ry="18" fill="#dae8fc" stroke="#6c8ebf" pointer-events="none"/><path d="M 512.25 102 L 521.72 102" fill="none" stroke="#000000" stroke-miterlimit="10" pointer-events="none"/><path d="M 525.66 102 L 520.41 104.63 L 521.72 102 L 520.41 99.38 Z" fill="#000000" stroke="#000000" stroke-miterlimit="10" pointer-events="none"/><rect x="0.75" y="42" width="120" height="120" rx="18" ry="18" fill="#dae8fc" stroke="#6c8ebf" pointer-events="none"/>
 <image xlink:href="https://1.bp.blogspot.com/-OBY7yjnWj9k/WCK6i_l0R9I/AAAAAAAAFLY/jCJwLNuPMecbvAB719g6VhAypmoDH6gswCLcB/s1600/x0.gif" x="8.25" y="49.5" width="105" height="105" fill="#f5f5f5" stroke="#666666" pointer-events="none"/>
 <image xlink:href="https://1.bp.blogspot.com/-WySijJ91Oa8/WCK6jFdXluI/AAAAAAAAFLc/CpaGjhd5lPwUdT6FdGNPQKRlyFhYvcwVQCLcB/s1600/x1.gif" x="534" y="49.5" width="105" height="105" fill="#f5f5f5" stroke="#666666" pointer-events="none"/>
 <image xlink:href="https://1.bp.blogspot.com/-tGqhaoX1a4Y/WCK6izWaixI/AAAAAAAAFLU/QRr6CzXET18_-c8hlx89QOkSQ3HoRH2DwCLcB/s1600/y.gif" x="293.25" y="6.75" width="64.5" height="190.5" fill="#f5f5f5" stroke="#666666" pointer-events="none"/></g></svg>
 #+END_HTML
#+END_CENTER

 #+BEGIN_NOTE
 ICLR17に *投稿中*, 2/3に採択結果判明
 #+END_NOTE

** Gumbel-Softmax

学習中に温度を下げていくことで *始めは自由に学習*

*そののち、精度を保ったまま中間層の分布をカテゴリカルに近づける*

[[spng:gumbel]]

#+BEGIN_ALIGNRIGHT
*カテゴリー2 → 0か1 の離散的分布になる → 命題にマップ可能*
#+END_ALIGNRIGHT

** Entire System

 [[png:overview/planning]]

* 評価

GTX1070, PhenomII X6 1060T, 16GB

+ Fast Downward :: LMcut heuristics, A*

+ State AutoEncoder :: Tensorflow, Keras, Adam optimizer (learning rate:0.001)

  784(84x84)

  →FC(1000,ReLu)→Batchnorm→Dropout(0.4)

  →FC(1000,ReLu)→Batchnorm→Dropout(0.4)

  →FC(25,GumbelSoftmax)

  →FC(1000,ReLu)→Batchnorm→Dropout(0.4)

  →FC(1000,ReLu)→Batchnorm→Dropout(0.4)

  →784(84x84) (loss: Binary crossentropy)

** 所要時間(目安)

 新しいシステムなので対戦相手が居ない...

 + State Autoencoder 学習時間: 1時間程度
 + MSDD Operator Acquisition (Lisp SBCL): 1時間程度
 + PDDL変換 (Lisp SBCL): 一瞬
 + Fast Downward: 2時間, メモリ1G程度で終了

** State AutoEncoder

1: Train入力 2: 生Latent 3: 生Autoencoding 4: 切り捨てLatent 5: 切り捨てLatentのAutoencoding

[[spng:experiment/autoencoding_train]]

** State AutoEncoder

1: Test入力 2: 生Latent 3: 生Autoencoding 4: 切り捨てLatent 5: 切り捨てLatentのAutoencoding

Test 入力: 訓練画像に含まれていない画像

[[spng:experiment/autoencoding_test]]

#+BEGIN_ALIGNRIGHT
きちんと学習できている
#+END_ALIGNRIGHT

** State AutoEncoder

入力2: 初期画像とゴール画像

[[spng:experiment/init_goal]]

** PDDL Domain Definition

#+BEGIN_SRC
  -rw-rw-r-- 1 guicho guicho  31M 2017-01-20 00:10 domain-all.pddl
#+END_SRC

#+BEGIN_SRC lisp
(define (domain latent)
 (:requirements :strips :negative-preconditions)
 (:predicates (z0) (z1) (z2) (z3) (z4) (z5) (z6) (z7) (z8) (z9) (z10)
  (z11) (z12) (z13) (z14) (z15) (z16) (z17) (z18) (z19) (z20) (z21)
  (z22) (z23) (z24))
 (:action a10000010010110111100011111000010001011111110011111
  :parameters () :precondition
  (and (z0) (not (z1)) (not (z2)) (not (z3)) (not (z4)) (not (z5))
       (z6) (not (z7)) (not (z8)) (z9) (not (z10)) (z11) (z12)
       (not (z13)) (z14) (z15) (z16) (z17) (not (z18)) (not (z19))
       (not (z20)) (z21) (z22) (z23) (z24))
  :effect (and (z5) (not (z6)) (z13) (z20)))
 (:action a10000010010110111100011110000001001011011110001110
  ...
#+END_SRC

** Fast Downward Log Trace (Search Statistics)

#+BEGIN_SRC
reading input... [t=5.479e-05 (sec)]
...
Building successor generator...done! [t=31.7737 (sec)]
done initalizing global data [t=31.7738 (sec)]
Conducting best first search with reopening closed nodes, (real) bound = 2147483647
Initializing landmark cut heuristic...
f = 4 [1 evaluated, 0 expanded, t=36.1569 (sec), 1054016 KB]
...
f = 12 [339 evaluated, 183 expanded, t=843.001 (sec), 1054016 KB]
f = 13 [553 evaluated, 314 expanded, t=1357.62 (sec), 1054016 KB]
f = 14 [942 evaluated, 529 expanded, t=2288.7 (sec), 1054016 KB]
Solution found!
Actual search time: 2688.73 (sec) [t=2724.89 (sec)]
a11010000010010000101001111101100010001000010100111 (1)
...
a10011100111110010010011011001111010111011001001111 (1)
a10011110101110110010011111001011001111011001001111 (1)
Plan length: 14 step(s).
Expanded 631 state(s).
Evaluated 1140 state(s).
Generated 1924 state(s).
Dead ends: 24 state(s).
Search time: 2693.06 (sec)
Total time: 2724.89 (sec)
#+END_SRC

** Plan Results

[[spng:experiment/plan]]

* Conclusion

+ Proposed a new system that solves a combinatorial problem proposed as raw images
+ Should be a milestone toward symbol grounding problem

* セミファイナル                                                   :noexport:

死んでると思ってたセミが実は生きてて

びっくりしたことはありませんか?

#+BEGIN_ALIGNRIGHT
Credit: http://hukaimandara.jugem.jp/?eid=92
#+END_ALIGNRIGHT

[[sjpg:semifinal]]

** セミファイナル


#+BEGIN_ALIGNRIGHT
Credit: http://hukaimandara.jugem.jp/?eid=92
#+END_ALIGNRIGHT

[[jpg:static/cicada]]

#+BEGIN_ALIGNRIGHT
+ 教訓: 複雑な3次元データは *足を開いている/死んでいる*

  という *1bit* のデータに要約できる → 命題そのもの
#+END_ALIGNRIGHT

# * Latent Space $L$ of an original state space $S$
# 
# #+BEGIN_QUOTE
# Apparently very complex $S$ can be described by low-dimentional $L$
# #+END_QUOTE
# 
# [[jpg:static/cicada]]

* /Manifold Hypothesis/ マニホールド仮説 and /Latent Space/        :noexport:

+ $x$: 高次元vector (例: 28x28 の画像データ = 784次元)
+ マニホールド仮説:
  + 世の中の高次元データは低次元にマッピングできる *はず*
  + 一見複雑なデータも実は少ないパラメータで説明できる 
+ $z$: 低次元 *Latent Space* vector (下の図では 2次元)
+ *この扱いやすい低次元ベクトルが欲しい*
  + セミファイナルの見分け方に相当

#+BEGIN_ALIGNRIGHT
+ ← Deep Learning で $z$ を見つける
#+END_ALIGNRIGHT

# $x$: high dimensional vector in $S$, $z$ in manifold $L$
# 
# Data is concentrated around a low dimensional manifold
# 
# Hope finding a representation Z of that manifold.

#+BEGIN_ALIGNRIGHT
http://www.deeplearningbook.org/ and VAE tutorial
#+END_ALIGNRIGHT

[[png:static/manifold]]

** Manifold Hypothesis

 $x$: high dimensional vector in $S$, $z$: manifold $L$

 Data is concentrated around a low dimensional manifold

 Hope finding a representation Z of that manifold.

 http://www.deeplearningbook.org/ and VAE tutorial

 [[png:static/manifold2]]

** Latent Space の威力

 #+BEGIN_SMALLER
 Reinforcement Learning(RL) in Latent Space (e.g. Luck IROS14, AAAI16)
 #+END_SMALLER

 強化学習(RL)を高次元に直接適用するのは難しい → PCA で得たLatent Space でRL

 (PCA: 一段 かつ 活性化関数無しのNNと考えられる 古いタイプの Latent Space 学習手法)

 　

 mapping 62-DOF space → 2D

 [[png:static/latent-RL]]

** Autoencoder

#+BEGIN_CENTER
*教師なし学習*

入力空間 *S* を Latent Space *L* に *圧縮*

かつ *S* に *展開* して *元の画像に損失無く戻す。*
#+END_CENTER

#+BEGIN_CONTAINER-FLUID
#+BEGIN_ROW-FLUID
#+BEGIN_SPAN3

#+END_SPAN3
#+BEGIN_SPAN6
[[png:static/autoenc]]
#+END_SPAN6
#+BEGIN_SPAN3

#+END_SPAN3
#+END_ROW-FLUID
#+END_CONTAINER-FLUID

#+BEGIN_ALIGNRIGHT
→ *データ* $x$ を *Latent vector* $z$ に変換/逆変換するNNを学習
#+END_ALIGNRIGHT

** Deep Autoencoder

 いろいろな追加技術を使うことでDeepにできる → *より圧縮できる*

 Stacked AE, pretraining, CNN, dropout, Batch-Normalization, GPU...

 [[png:static/deep-ae]]

* How?                                                             :noexport:

Simply put: discretize $z$ into SAS variables

Below: results of encoding a MNIST image (784-variable) to 2 variables

Mapping the input image to latent space (encoding part)

[[png:static/vae-latent]]

* How?                                                             :noexport:

Mapping the latent space to the actual image (decoding part)

[[png:static/vae-manifold]]

* 副産物: bit-ops

MSDD アルゴリズムを実装する上で *bit-vector* を効率よく扱う必要が出来た

+ Common Lisp における bit-vector : C における short 配列に相当
  + Sequenceとして扱える: *fill,map,replace...*
  + ビット演算が標準に含まれている: *bit-and, bit-xor...* ループを書く必要がない
  + コンパイラが64ビットの整数処理に自動変換してくれる(のでCと同様に速い)

** Common Lisp の bit-wise 演算

#+BEGIN_SRC lisp
(bit-and x y &optional z)
#+END_SRC

bit vector =x= と =y= の論理和を取る

z が与えられていれば、 結果を *z に破壊的に代入* しそれを返す

# z が シンボル =t= のときは、 結果は =x= に破壊的に代入される

z が省略された時は *新たなベクトル* を生成して返す

** 注意して使わないと…

大量のconsing: 中間結果がヒープに確保される

#+BEGIN_SRC lisp
(bit-and (bit-xor x y) z)

-> 以下と同様

(let ((tmp  (make-array (length x) :element-type 'bit)) ; ヒープ
      (tmp2 (make-array (length x) :element-type 'bit))); ヒープ

  (bit-xor x y tmp)
  (bit-and tmp z tmp2)
  tmp2)
#+END_SRC

** 対処法

dynamic-extent 宣言で中間ベクトルをスタック配置

#+BEGIN_SRC lisp
(bit-and (bit-xor x y) z)

-> 以下と同様

(let ((tmp  (make-array (length x) :element-type 'bit))
      (tmp2 (make-array (length x) :element-type 'bit)))
  (declare (dynamic-extent tmp tmp2))
  (bit-xor x y tmp)
  (bit-and tmp z tmp2)
  tmp2)
#+END_SRC

** ほかにもいろいろ最適化出来る

中間ベクトルの再利用

#+BEGIN_SRC lisp
(bit-and (bit-xor x y) z)

-> 以下と同様

(let ((tmp  (make-array (length x) :element-type 'bit)))
  (declare (dynamic-extent tmp))
  (bit-xor x y tmp)
  (bit-and tmp z tmp)  ; tmp を再利用 → スタックを節約
  tmp)
#+END_SRC

#+BEGIN_CENTER
+ *こんな小手先の最適化は研究の本質じゃない! 自動化したい!*
#+END_CENTER

** 拙作 bit-ops: *ビット演算コンパイラ*

#+BEGIN_SRC lisp
(as-bitwise-operations (&key result)
  &body)
#+END_SRC

=&body= にビット演算を書くと *自動で速いプログラムに書きなおしてくれる* マクロ

内部的にはSSAっぽく計算を保持

中間ベクトルの再利用 (スタック消費を抑える) → コンパイラのレジスタ配置に相当

共通部分式除去 → 例: =(and a b)= が二度現れたら一度だけ計算して結果を再利用

** 例1:

#+BEGIN_SRC lisp
(as-bitwise-operations ()
  (and a b c))

-> 展開 (コンパイル)

(LET* ((#:LEN835 (LENGTH C))
       ;; 自動で生成された変数。
       ;; 結果として返されるベクトルなので、ヒープに。
       (#:G833 (MAKE-BIT-VECTOR #:LEN835)))
   (BIT-AND B C #:G833)
   (BIT-AND A #:G833 #:G833) ; 中間結果は再利用
   #:G833)
#+END_SRC

** 例2:

#+BEGIN_SRC lisp
(as-bitwise-operations (:result c) ; 結果を c に書き込むよう指定
  (and a b c))

->

(LET* ((#:LEN835 (LENGTH C))
       ;; 自動で生成された変数。
       ;; 結果はcに書き戻される
       (#:G833 C))
   (BIT-AND B C #:G833)
   (BIT-AND A #:G833 #:G833) ; 中間結果は再利用
   #:G833)
#+END_SRC

** 例3: a が 1 なら b を、 0 なら c を取る操作 (if-then-else)

#+BEGIN_SRC lisp
(as-bitwise-operations ()
  (ior (and a b)
       (and (not a) c)))

->

(LET* ((#:LEN700 (LENGTH C))
       (#:G701 (MAKE-BIT-VECTOR #:LEN700)))
  (LET* ((#:G702 (MAKE-BIT-VECTOR #:LEN700)))
    (DECLARE (DYNAMIC-EXTENT #:G702))  ; 中間結果G747はスタック配置
    (BIT-AND A B #:G701)           ; 結果ベクトルG701再利用
    (BIT-NOT A #:G702)
    (BIT-AND #:G702 C #:G702)      ; 中間ベクトルG702再利用
    (BIT-IOR #:G701 #:G702 #:G701) ; 結果ベクトルG701再利用
    #:G701))
#+END_SRC

** ビット演算用のDSLを拡張できる

#+BEGIN_SRC lisp
(define-bitwise-operation if (condition then else)
  `(ior (and ,condition ,then)
        (and (not ,condition) ,else)))

これで

(as-bitwise-operations (:result c)
  (ior (and a b)
       (and (not a) c)))

のかわりに

(as-bitwise-operations (:result c)
  (if a b c))

と書ける
#+END_SRC

** 半加算器

[[spng:halfadder]]

#+BEGIN_SRC lisp
(define-bitwise-operation half-adder-sum (a b)
  "sum output of half adder "
  `(xor ,a ,b))
(define-bitwise-operation half-adder-carry (a b)
  "carry output of half adder "
  `(and ,a ,b))
#+END_SRC

** 半加算器を使って全加算器を書く

[[spng:fulladder]]

#+BEGIN_SRC lisp
(define-bitwise-operation full-adder-sum (a b x)
  "sum output of full adder "
  `(half-adder-sum (half-adder-sum ,a ,b)
                   ,x))

(define-bitwise-operation full-adder-carry (a b x)
  "carry output of full adder "
  `(ior (half-adder-carry ,a ,b)
        (half-adder-carry (half-adder-sum ,a ,b)
                          ,x)))
#+END_SRC

** 全加算器を使って2段加算器を書く

[[spng:adder6]]


#+BEGIN_SRC lisp
(as-bitwise-operations ()
  (full-adder-sum (subseq a 1)
                  (subseq b 1)
                  (half-adder-carry a b)))

->

(LET* ((#:*LENGTH-VARIABLE*723 (LENGTH B))
       (#:G727 (MAKE-BIT-VECTOR #:*LENGTH-VARIABLE*723)))
  (LET* ((#:G725 (MAKE-BIT-VECTOR #:*LENGTH-VARIABLE*723))
         (#:G724 (MAKE-BIT-VECTOR #:*LENGTH-VARIABLE*723)))
    (DECLARE (DYNAMIC-EXTENT #:G725 #:G724))
    (BIT-REPLACE A 1 #:G724)
    (BIT-REPLACE B 1 #:G725)
    (BIT-XOR #:G724 #:G725 #:G724)
    (BIT-AND A B #:G727)
    (BIT-XOR #:G724 #:G727 #:G727)
    #:G727))
#+END_SRC

** n段加算器を書く

[[spng:adder6]]

どんどん拡張できる!

#+BEGIN_SRC lisp
(as-bitwise-operations ()
  (full-adder-sum (subseq a 1)
                  (subseq b 1)
                  (half-adder-carry a b)))

(define-bitwise-operation multi-adder-sum (a b n)
  (if (= n 0)
      `(half-adder-sum ,a ,b)
      `(full-adder-sum (subseq ,a ,n)
                       (subseq ,b ,n)
                       (multi-adder-carry ,a ,b ,(1- n)))))

(define-bitwise-operation multi-adder-carry (a b n)
  ...)
#+END_SRC

** n段加算器を書く


[[spng:adder6]]

どんどん拡張できる!

#+BEGIN_SRC lisp
(as-bitwise-operations ()
  (multi-adder-sum a b 5))

(LET* ((#:*LENGTH-VARIABLE*844 (LENGTH B))
       (#:G881 (MAKE-BIT-VECTOR #:*LENGTH-VARIABLE*844)))
  (LET* ((#:G845 (MAKE-BIT-VECTOR #:*LENGTH-VARIABLE*844))
         ...
         (#:G872 (MAKE-BIT-VECTOR #:*LENGTH-VARIABLE*844)))
    (DECLARE
     (DYNAMIC-EXTENT #:G845 ... #:G872))
    (BIT-REPLACE A 5 #:G845)
    (BIT-REPLACE B 5 #:G846)
    (BIT-XOR #:G845 #:G846 #:G845)
    ...
    (BIT-AND #:G866 #:G867 #:G868)
    (BIT-XOR #:G866 #:G867 #:G871)
    (BIT-AND A B #:G872)
    (BIT-AND #:G871 #:G872 #:G871)
    (BIT-IOR #:G868 #:G871 #:G868)
    (BIT-AND #:G865 #:G868 #:G865)
    (BIT-IOR #:G862 #:G865 #:G862)
    (BIT-AND #:G859 #:G862 #:G859)
    (BIT-IOR #:G856 #:G859 #:G856)
    (BIT-AND #:G853 #:G856 #:G853)
    (BIT-IOR #:G850 #:G853 #:G850)
    (BIT-XOR #:G845 #:G850 #:G881)
    #:G881))
#+END_SRC

** まとめ

+ DeepLearning + Planning を実装する上で MSDD を実装
+ MSDD のために 早い bit-vector 操作が必要だった
+ bit-vector の操作を SIMD的に最適化するマクロ bit-ops を開発した




* 最後に

#+BEGIN_XLARGE
東京大学
#+BEGIN_CENTER
総合文化研究科 広域科学専攻
#+END_CENTER
#+BEGIN_ALIGNRIGHT
の宣伝
#+END_ALIGNRIGHT
#+END_XLARGE

** 入試が簡単!

[[spng:p13]]

** Lisper 歓迎!

[[spng:cl-mpi]]

** 

#+BEGIN_XLARGE
東京大学
#+BEGIN_CENTER
総合文化研究科 広域科学専攻
#+END_CENTER
#+BEGIN_ALIGNRIGHT
Welcome!
#+END_ALIGNRIGHT
#+END_XLARGE
